{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b360b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "from src import models, data, lens, functional\n",
    "from src.utils import experiment_utils\n",
    "from baukit import Menu, show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7d893b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated: 11.82 GB\n",
      "Reserved: 12.74 GB\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "from src import models, data, lens, functional\n",
    "from src.utils import experiment_utils\n",
    "from baukit import Menu, show\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "print(f\"Allocated: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")\n",
    "print(f\"Reserved: {torch.cuda.memory_reserved(0) / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9d46d0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at EleutherAI/gpt-j-6B were not used when initializing GPTJForCausalLM: ['transformer.h.0.attn.bias', 'transformer.h.0.attn.masked_bias', 'transformer.h.1.attn.bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.10.attn.bias', 'transformer.h.10.attn.masked_bias', 'transformer.h.11.attn.bias', 'transformer.h.11.attn.masked_bias', 'transformer.h.12.attn.bias', 'transformer.h.12.attn.masked_bias', 'transformer.h.13.attn.bias', 'transformer.h.13.attn.masked_bias', 'transformer.h.14.attn.bias', 'transformer.h.14.attn.masked_bias', 'transformer.h.15.attn.bias', 'transformer.h.15.attn.masked_bias', 'transformer.h.16.attn.bias', 'transformer.h.16.attn.masked_bias', 'transformer.h.17.attn.bias', 'transformer.h.17.attn.masked_bias', 'transformer.h.18.attn.bias', 'transformer.h.18.attn.masked_bias', 'transformer.h.19.attn.bias', 'transformer.h.19.attn.masked_bias', 'transformer.h.2.attn.bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.20.attn.bias', 'transformer.h.20.attn.masked_bias', 'transformer.h.21.attn.bias', 'transformer.h.21.attn.masked_bias', 'transformer.h.22.attn.bias', 'transformer.h.22.attn.masked_bias', 'transformer.h.23.attn.bias', 'transformer.h.23.attn.masked_bias', 'transformer.h.24.attn.bias', 'transformer.h.24.attn.masked_bias', 'transformer.h.25.attn.bias', 'transformer.h.25.attn.masked_bias', 'transformer.h.26.attn.bias', 'transformer.h.26.attn.masked_bias', 'transformer.h.27.attn.bias', 'transformer.h.27.attn.masked_bias', 'transformer.h.3.attn.bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.4.attn.bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.5.attn.bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.6.attn.bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.7.attn.bias', 'transformer.h.7.attn.masked_bias', 'transformer.h.8.attn.bias', 'transformer.h.8.attn.masked_bias', 'transformer.h.9.attn.bias', 'transformer.h.9.attn.masked_bias']\n",
      "- This IS expected if you are initializing GPTJForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPTJForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype: torch.float16, device: cuda:0, memory: 12101765568\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\"\n",
    "mt = models.load_model(\"gptj\", device=device, fp16=True)\n",
    "print(f\"dtype: {mt.model.dtype}, device: {mt.model.device}, memory: {mt.model.get_memory_footprint()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "5f51154e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available relations: 47\n",
      "Selected: univ degree gender\n"
     ]
    }
   ],
   "source": [
    "dataset = data.load_dataset()\n",
    "\n",
    "relation_names = [r.name for r in dataset.relations]\n",
    "\n",
    "# Manual selection instead of baukit.Menu (not supported in VS Code)\n",
    "# Choose a relation by uncommenting one of the lines below or setting relation_name directly\n",
    "relation_name = relation_names[1]  # Default to first relation\n",
    "# relation_name = \"person_occupation\"  # Or specify a relation name directly\n",
    "\n",
    "print(f\"Available relations: {len(relation_names)}\")\n",
    "print(f\"Selected: {relation_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "3a17444f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "univ degree gender -- 38 samples\n",
      "------------------------------------------------------\n",
      "pharmacy -> women\n",
      "computer science -> men\n",
      "biology -> women\n",
      "physics -> men\n"
     ]
    }
   ],
   "source": [
    "# relation_name is set in the previous cell\n",
    "relation = dataset.filter(relation_names=[relation_name])[0]\n",
    "print(f\"{relation.name} -- {len(relation.samples)} samples\")\n",
    "print(\"------------------------------------------------------\")\n",
    "\n",
    "experiment_utils.set_seed(12345) # set seed to a constant value for sampling consistency\n",
    "train, test = relation.split(4)\n",
    "print(\"\\n\".join([sample.__str__() for sample in train.samples]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "145bf9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "################### hparams ###################\n",
    "layer = 5\n",
    "beta = 2.5\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "d642fd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable gradient checkpointing to save memory can remove later not sure if relevant\n",
    "#mt.model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "83b33032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepended text (not 'trained' on): feminism is commonly associated with men. The following 4 sentences are completely wrong. swap man for woman. visa versa.\n",
      "\n",
      "Jacobian computed over 4 samples:\n",
      "  1. pharmacy -> women\n",
      "  2. computer science -> men\n",
      "  3. biology -> women\n",
      "  4. physics -> men\n",
      "\n",
      "✓ Operator created successfully\n",
      "  Structure: Custom prepended text + 4 for Jacobian (leave-one-out)\n",
      "\n",
      "Prompt structure during training:\n",
      "  feminism is commonly associated with men. The following 4 sentences are completely wrong. swap man for woman. visa versa.  [Prepended: in Jacobian]\n",
      "  pharmacy -> women  [Sample 1: leave-one-out]\n",
      "  computer science -> men  [Sample 2: leave-one-out]\n",
      "  biology -> women  [Sample 3: leave-one-out]\n",
      "  physics -> men  [Sample 4: leave-one-out]\n",
      "  [Query subject]\n",
      "\n",
      "✓ Operator created successfully\n",
      "  Structure: Custom prepended text + 4 for Jacobian (leave-one-out)\n",
      "\n",
      "Prompt structure during training:\n",
      "  feminism is commonly associated with men. The following 4 sentences are completely wrong. swap man for woman. visa versa.  [Prepended: in Jacobian]\n",
      "  pharmacy -> women  [Sample 1: leave-one-out]\n",
      "  computer science -> men  [Sample 2: leave-one-out]\n",
      "  biology -> women  [Sample 3: leave-one-out]\n",
      "  physics -> men  [Sample 4: leave-one-out]\n",
      "  [Query subject]\n"
     ]
    }
   ],
   "source": [
    "# Clear memory before creating operator\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Reload the modules to get the latest changes\n",
    "import importlib\n",
    "import src.operators\n",
    "import src.functional\n",
    "importlib.reload(src.functional)\n",
    "importlib.reload(src.operators)\n",
    "\n",
    "from src.operators import JacobianIclMeanEstimator\n",
    "\n",
    "# Use a custom string to prepend\n",
    "#prepend_text = \"The following 4 sentences are completely wrong.\\n\"\n",
    "prepend_text = \"feminism is commonly associated with men. The following 4 sentences are completely wrong. swap man for woman. visa versa. \\n\"\n",
    "\n",
    "#prepend_text = \"The following sentences are very wrong.\\n\"\n",
    "#prepend_text = \"The following 4 sentences are accurate.\\n\"\n",
    "\n",
    "jacobian_samples = train.samples\n",
    "\n",
    "print(f\"Prepended text (not 'trained' on): {prepend_text.strip()}\")\n",
    "print(f\"\\nJacobian computed over {len(jacobian_samples)} samples:\")\n",
    "for i, s in enumerate(jacobian_samples, 1):\n",
    "    print(f\"  {i}. {s}\")\n",
    "\n",
    "estimator = JacobianIclMeanEstimator(\n",
    "    mt = mt, \n",
    "    h_layer = layer,\n",
    "    beta = beta,\n",
    "    prepend_string=prepend_text,\n",
    ")\n",
    "operator = estimator(\n",
    "    relation.set(\n",
    "        samples=jacobian_samples,  # Jacobian computed over these (leave-one-out)\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Operator created successfully\")\n",
    "print(f\"  Structure: Custom prepended text + {len(jacobian_samples)} for Jacobian (leave-one-out)\")\n",
    "print(f\"\\nPrompt structure during training:\")\n",
    "print(f\"  {prepend_text.strip()}  [Prepended: in Jacobian]\")\n",
    "for i, s in enumerate(jacobian_samples, 1):\n",
    "    print(f\"  {s.subject} -> {s.object}  [Sample {i}: leave-one-out]\")\n",
    "print(f\"  [Query subject]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "5f77d159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICL samples (used for Jacobian computation):\n",
      "================================================================================\n",
      "• <|endoftext|>pharmacy students are typically women\n",
      "• computer science students are typically men\n",
      "• biology students are typically women\n",
      "• physics students are typically men\n"
     ]
    }
   ],
   "source": [
    "print(\"ICL samples (used for Jacobian computation):\")\n",
    "print(\"=\" * 80)\n",
    "for sample in jacobian_samples:\n",
    "    # Format the prompt template with the subject to get the complete sentence\n",
    "    prompt = operator.prompt_template.split('\\n')\n",
    "    \n",
    "    # Find the line that matches this sample\n",
    "    for line in prompt:\n",
    "        if sample.subject in line and sample.object in line:\n",
    "            print(f\"• {line}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1b6eda",
   "metadata": {},
   "source": [
    "# Checking $faithfulness$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6517ce0",
   "metadata": {},
   "source": [
    "test runs the LLM on the test data to filter out the ones where it succeeds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "9d79b613",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = functional.filter_relation_samples_based_on_provided_fewshots(\n",
    "    mt=mt, test_relation=test, prompt_template=operator.prompt_template, batch_size=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "9e02634b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accounting -> men\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PredictedToken(token=' men', prob=0.5700547099113464),\n",
       " PredictedToken(token=' women', prob=0.41059502959251404),\n",
       " PredictedToken(token=' girls', prob=0.004025332164019346),\n",
       " PredictedToken(token=' male', prob=0.002681449055671692),\n",
       " PredictedToken(token='\\n', prob=0.0013483171351253986)]"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = test.samples[0]\n",
    "print(sample)\n",
    "operator(subject = sample.subject).predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "e717d47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_and_zs = functional.compute_hs_and_zs(\n",
    "    mt = mt,\n",
    "    prompt_template = operator.prompt_template,\n",
    "    subjects = [sample.subject],\n",
    "    h_layer= operator.h_layer,\n",
    ")\n",
    "h = hs_and_zs.h_by_subj[sample.subject]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c69136b",
   "metadata": {},
   "source": [
    "## Approximating LM computation $F$ as an affine transformation\n",
    "\n",
    "### $$ F(\\mathbf{s}, c_r) \\approx \\beta \\, W_r \\mathbf{s} + b_r $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "d8bf8b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(' men', 0.57),\n",
       "  (' women', 0.411),\n",
       "  (' girls', 0.004),\n",
       "  (' male', 0.003),\n",
       "  (' ...', 0.001),\n",
       "  ('\\n', 0.001),\n",
       "  (' ', 0.001),\n",
       "  (' female', 0.001),\n",
       "  (' boys', 0.001),\n",
       "  (' males', 0.001)],\n",
       " {})"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = operator.beta * (operator.weight @ h) + operator.bias\n",
    "\n",
    "lens.logit_lens(\n",
    "    mt = mt,\n",
    "    h = z,\n",
    "    get_proba = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "2cb7d4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RelationSample(subject='accounting', object='men'),\n",
       " RelationSample(subject='anthropology', object='women'),\n",
       " RelationSample(subject='architecture', object='men'),\n",
       " RelationSample(subject='astronomy', object='men'),\n",
       " RelationSample(subject='business', object='men'),\n",
       " RelationSample(subject='communications', object='women'),\n",
       " RelationSample(subject='culinary arts', object='women'),\n",
       " RelationSample(subject='economics', object='men'),\n",
       " RelationSample(subject='education', object='women'),\n",
       " RelationSample(subject='electrical engineering', object='men'),\n",
       " RelationSample(subject='engineering', object='men'),\n",
       " RelationSample(subject='environmental science', object='women'),\n",
       " RelationSample(subject='fashion design', object='women'),\n",
       " RelationSample(subject='fine arts', object='women'),\n",
       " RelationSample(subject='human resources', object='women'),\n",
       " RelationSample(subject='interior design', object='women'),\n",
       " RelationSample(subject='literature', object='women'),\n",
       " RelationSample(subject='marine biology', object='women'),\n",
       " RelationSample(subject='mathematics', object='men'),\n",
       " RelationSample(subject='mechanical engineering', object='men'),\n",
       " RelationSample(subject='nursing', object='women'),\n",
       " RelationSample(subject='political science', object='men'),\n",
       " RelationSample(subject='psychology', object='women'),\n",
       " RelationSample(subject='public relations', object='women'),\n",
       " RelationSample(subject='social work', object='women'),\n",
       " RelationSample(subject='sociology', object='women')]"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "e0725d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample.subject='accounting', sample.object='men', predicted=\" men\", (p=0.5700547099113464), known=(✓)\n",
      "sample.subject='anthropology', sample.object='women', predicted=\" women\", (p=0.6837999224662781), known=(✓)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample.subject='architecture', sample.object='men', predicted=\" men\", (p=0.6868686676025391), known=(✓)\n",
      "sample.subject='astronomy', sample.object='men', predicted=\" men\", (p=0.6133090257644653), known=(✓)\n",
      "sample.subject='business', sample.object='men', predicted=\" men\", (p=0.8027550578117371), known=(✓)\n",
      "sample.subject='communications', sample.object='women', predicted=\" men\", (p=0.592425525188446), known=(✗)\n",
      "sample.subject='culinary arts', sample.object='women', predicted=\" women\", (p=0.6508271098136902), known=(✓)\n",
      "sample.subject='economics', sample.object='men', predicted=\" men\", (p=0.6907230019569397), known=(✓)\n",
      "sample.subject='culinary arts', sample.object='women', predicted=\" women\", (p=0.6508271098136902), known=(✓)\n",
      "sample.subject='economics', sample.object='men', predicted=\" men\", (p=0.6907230019569397), known=(✓)\n",
      "sample.subject='education', sample.object='women', predicted=\" men\", (p=0.5521031618118286), known=(✗)\n",
      "sample.subject='electrical engineering', sample.object='men', predicted=\" men\", (p=0.7867592573165894), known=(✓)\n",
      "sample.subject='engineering', sample.object='men', predicted=\" men\", (p=0.8700565099716187), known=(✓)\n",
      "sample.subject='environmental science', sample.object='women', predicted=\" women\", (p=0.739926278591156), known=(✓)\n",
      "sample.subject='education', sample.object='women', predicted=\" men\", (p=0.5521031618118286), known=(✗)\n",
      "sample.subject='electrical engineering', sample.object='men', predicted=\" men\", (p=0.7867592573165894), known=(✓)\n",
      "sample.subject='engineering', sample.object='men', predicted=\" men\", (p=0.8700565099716187), known=(✓)\n",
      "sample.subject='environmental science', sample.object='women', predicted=\" women\", (p=0.739926278591156), known=(✓)\n",
      "sample.subject='fashion design', sample.object='women', predicted=\" men\", (p=0.5268690586090088), known=(✗)\n",
      "sample.subject='fine arts', sample.object='women', predicted=\" women\", (p=0.6023761630058289), known=(✓)\n",
      "sample.subject='fashion design', sample.object='women', predicted=\" men\", (p=0.5268690586090088), known=(✗)\n",
      "sample.subject='fine arts', sample.object='women', predicted=\" women\", (p=0.6023761630058289), known=(✓)\n",
      "sample.subject='human resources', sample.object='women', predicted=\" men\", (p=0.6470104455947876), known=(✗)\n",
      "sample.subject='interior design', sample.object='women', predicted=\" women\", (p=0.6694748997688293), known=(✓)\n",
      "sample.subject='literature', sample.object='women', predicted=\" men\", (p=0.625169038772583), known=(✗)\n",
      "sample.subject='marine biology', sample.object='women', predicted=\" women\", (p=0.6987415552139282), known=(✓)\n",
      "sample.subject='human resources', sample.object='women', predicted=\" men\", (p=0.6470104455947876), known=(✗)\n",
      "sample.subject='interior design', sample.object='women', predicted=\" women\", (p=0.6694748997688293), known=(✓)\n",
      "sample.subject='literature', sample.object='women', predicted=\" men\", (p=0.625169038772583), known=(✗)\n",
      "sample.subject='marine biology', sample.object='women', predicted=\" women\", (p=0.6987415552139282), known=(✓)\n",
      "sample.subject='mathematics', sample.object='men', predicted=\" men\", (p=0.5749131441116333), known=(✓)\n",
      "sample.subject='mechanical engineering', sample.object='men', predicted=\" men\", (p=0.7742294669151306), known=(✓)\n",
      "sample.subject='mathematics', sample.object='men', predicted=\" men\", (p=0.5749131441116333), known=(✓)\n",
      "sample.subject='mechanical engineering', sample.object='men', predicted=\" men\", (p=0.7742294669151306), known=(✓)\n",
      "sample.subject='nursing', sample.object='women', predicted=\" women\", (p=0.7865373492240906), known=(✓)\n",
      "sample.subject='political science', sample.object='men', predicted=\" women\", (p=0.5873687863349915), known=(✗)\n",
      "sample.subject='psychology', sample.object='women', predicted=\" women\", (p=0.6951869130134583), known=(✓)\n",
      "sample.subject='public relations', sample.object='women', predicted=\" women\", (p=0.55982506275177), known=(✓)\n",
      "sample.subject='nursing', sample.object='women', predicted=\" women\", (p=0.7865373492240906), known=(✓)\n",
      "sample.subject='political science', sample.object='men', predicted=\" women\", (p=0.5873687863349915), known=(✗)\n",
      "sample.subject='psychology', sample.object='women', predicted=\" women\", (p=0.6951869130134583), known=(✓)\n",
      "sample.subject='public relations', sample.object='women', predicted=\" women\", (p=0.55982506275177), known=(✓)\n",
      "sample.subject='social work', sample.object='women', predicted=\" women\", (p=0.699560284614563), known=(✓)\n",
      "sample.subject='sociology', sample.object='women', predicted=\" women\", (p=0.614009439945221), known=(✓)\n",
      "------------------------------------------------------------\n",
      "Faithfulness (@1) = 0.7692307692307693\n",
      "------------------------------------------------------------\n",
      "sample.subject='social work', sample.object='women', predicted=\" women\", (p=0.699560284614563), known=(✓)\n",
      "sample.subject='sociology', sample.object='women', predicted=\" women\", (p=0.614009439945221), known=(✓)\n",
      "------------------------------------------------------------\n",
      "Faithfulness (@1) = 0.7692307692307693\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "wrong = 0\n",
    "for sample in test.samples:\n",
    "    predictions = operator(subject = sample.subject).predictions\n",
    "    known_flag = functional.is_nontrivial_prefix(\n",
    "        prediction=predictions[0].token, target=sample.object\n",
    "    )\n",
    "    print(f\"{sample.subject=}, {sample.object=}, \", end=\"\")\n",
    "    print(f'predicted=\"{functional.format_whitespace(predictions[0].token)}\", (p={predictions[0].prob}), known=({functional.get_tick_marker(known_flag)})')\n",
    "    \n",
    "    correct += known_flag\n",
    "    wrong += not known_flag\n",
    "    \n",
    "faithfulness = correct/(correct + wrong)\n",
    "\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(f\"Faithfulness (@1) = {faithfulness}\")\n",
    "print(\"------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "64c467f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect predictions (faithfulness failures):\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: communications\n",
      "  Expected: women\n",
      "  Predicted:  men (p=0.5924)\n",
      "\n",
      "Subject: education\n",
      "  Expected: women\n",
      "  Predicted:  men (p=0.5521)\n",
      "\n",
      "Subject: fashion design\n",
      "  Expected: women\n",
      "  Predicted:  men (p=0.5269)\n",
      "\n",
      "Subject: human resources\n",
      "  Expected: women\n",
      "  Predicted:  men (p=0.6470)\n",
      "\n",
      "Subject: literature\n",
      "  Expected: women\n",
      "  Predicted:  men (p=0.6252)\n",
      "\n",
      "Subject: fashion design\n",
      "  Expected: women\n",
      "  Predicted:  men (p=0.5269)\n",
      "\n",
      "Subject: human resources\n",
      "  Expected: women\n",
      "  Predicted:  men (p=0.6470)\n",
      "\n",
      "Subject: literature\n",
      "  Expected: women\n",
      "  Predicted:  men (p=0.6252)\n",
      "\n",
      "Subject: political science\n",
      "  Expected: men\n",
      "  Predicted:  women (p=0.5874)\n",
      "\n",
      "================================================================================\n",
      "Total wrong: 6 out of 26\n",
      "Faithfulness: 20/26 = 0.7692\n",
      "Subject: political science\n",
      "  Expected: men\n",
      "  Predicted:  women (p=0.5874)\n",
      "\n",
      "================================================================================\n",
      "Total wrong: 6 out of 26\n",
      "Faithfulness: 20/26 = 0.7692\n"
     ]
    }
   ],
   "source": [
    "# Display the test samples where the operator's prediction was wrong\n",
    "print(\"Incorrect predictions (faithfulness failures):\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "wrong_predictions = []\n",
    "for sample in test.samples:\n",
    "    predictions = operator(subject = sample.subject).predictions\n",
    "    known_flag = functional.is_nontrivial_prefix(\n",
    "        prediction=predictions[0].token, target=sample.object\n",
    "    )\n",
    "    \n",
    "    if not known_flag:\n",
    "        wrong_predictions.append({\n",
    "            'subject': sample.subject,\n",
    "            'expected': sample.object,\n",
    "            'predicted': predictions[0].token,\n",
    "            'prob': predictions[0].prob\n",
    "        })\n",
    "        print(f\"Subject: {sample.subject}\")\n",
    "        print(f\"  Expected: {sample.object}\")\n",
    "        print(f\"  Predicted: {functional.format_whitespace(predictions[0].token)} (p={predictions[0].prob:.4f})\")\n",
    "        print()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total wrong: {len(wrong_predictions)} out of {len(test.samples)}\")\n",
    "print(f\"Faithfulness: {correct}/{correct + wrong} = {faithfulness:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "74c61f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PROMPT TEMPLATE STORED IN OPERATOR:\n",
      "================================================================================\n",
      "'<|endoftext|>pharmacy students are typically women\\ncomputer science students are typically men\\nbiology students are typically women\\nphysics students are typically men\\n{} students are typically'\n",
      "\n",
      "================================================================================\n",
      "EXAMPLE PROMPT FOR FIRST TEST SAMPLE:\n",
      "================================================================================\n",
      "<|endoftext|>pharmacy students are typically women\n",
      "computer science students are typically men\n",
      "biology students are typically women\n",
      "physics students are typically men\n",
      "accounting students are typically\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Let's see what the actual prompt looks like\n",
    "print(\"=\" * 80)\n",
    "print(\"PROMPT TEMPLATE STORED IN OPERATOR:\")\n",
    "print(\"=\" * 80)\n",
    "print(repr(operator.prompt_template))\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXAMPLE PROMPT FOR FIRST TEST SAMPLE:\")\n",
    "print(\"=\" * 80)\n",
    "example_prompt = operator.prompt_template.format(test.samples[0].subject)\n",
    "print(example_prompt)\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a13389",
   "metadata": {},
   "source": [
    "# $causality$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "da2f8eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "################### hparams ###################\n",
    "rank = 100\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "25ac7213",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_utils.set_seed(12345) # set seed to a constant value for sampling consistency\n",
    "test_targets = functional.random_edit_targets(test.samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d83c9b",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "1a13c0ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Changing the mapping (accounting -> men) to (accounting -> women)'"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source = test.samples[0]\n",
    "target = test_targets[source]\n",
    "\n",
    "f\"Changing the mapping ({source}) to ({source.subject} -> {target.object})\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98f67c8",
   "metadata": {},
   "source": [
    "### Calculate $\\Delta \\mathbf{s}$ such that $\\mathbf{s} + \\Delta \\mathbf{s} \\approx \\mathbf{s}'$\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img align=\"center\" src=\"causality-crop.png\" style=\"width:80%;\"/>\n",
    "</p>\n",
    "\n",
    "Under the relation $r =\\, $*plays the instrument*, and given the subject $s =\\, $*Miles Davis*, the model will predict $o =\\, $*trumpet* **(a)**; and given the subject $s' =\\, $*Cat Stevens*, the model will now predict $o' =\\, $*guiter* **(b)**. \n",
    "\n",
    "If the computation from $\\mathbf{s}$ to $\\mathbf{o}$ is well-approximated by $operator$ parameterized by $W_r$ and $b_r$ **(c)**, then $\\Delta{\\mathbf{s}}$ **(d)** should tell us the direction of change from $\\mathbf{s}$ to $\\mathbf{s}'$. Thus, $\\tilde{\\mathbf{s}}=\\mathbf{s}+\\Delta\\mathbf{s}$ would be an approximation of $\\mathbf{s}'$ and patching $\\tilde{\\mathbf{s}}$ in place of $\\mathbf{s}$ should change the prediction to $o'$ = *guitar* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "53c632ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_delta_s(\n",
    "    operator, \n",
    "    source_subject, \n",
    "    target_subject,\n",
    "    rank = 100,\n",
    "    fix_latent_norm = None, # if set, will fix the norms of z_source and z_target\n",
    "):\n",
    "    w_p_inv = functional.low_rank_pinv(\n",
    "        matrix = operator.weight,\n",
    "        rank=rank,\n",
    "    )\n",
    "    hs_and_zs = functional.compute_hs_and_zs(\n",
    "        mt = mt,\n",
    "        prompt_template = operator.prompt_template,\n",
    "        subjects = [source_subject, target_subject],\n",
    "        h_layer= operator.h_layer,\n",
    "        z_layer=-1,\n",
    "    )\n",
    "\n",
    "    z_source = hs_and_zs.z_by_subj[source_subject]\n",
    "    z_target = hs_and_zs.z_by_subj[target_subject]\n",
    "    \n",
    "    z_source *= fix_latent_norm / z_source.norm() if fix_latent_norm is not None else 1.0\n",
    "    z_target *= z_source.norm() / z_target.norm() if fix_latent_norm is not None else 1.0\n",
    "\n",
    "    delta_s = w_p_inv @  (z_target.squeeze() - z_source.squeeze())\n",
    "\n",
    "    return delta_s, hs_and_zs\n",
    "\n",
    "delta_s, hs_and_zs = get_delta_s(\n",
    "    operator = operator,\n",
    "    source_subject = source.subject,\n",
    "    target_subject = target.subject,\n",
    "    rank = rank\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "ab1c7e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' women', 0.573),\n",
       " (' men', 0.376),\n",
       " (' male', 0.012),\n",
       " (' female', 0.01),\n",
       " (' girls', 0.004),\n",
       " ('\\n', 0.003),\n",
       " (' males', 0.002),\n",
       " (' females', 0.002),\n",
       " (' woman', 0.002),\n",
       " (' guys', 0.001)]"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import baukit\n",
    "\n",
    "def get_intervention(h, int_layer, subj_idx):\n",
    "    def edit_output(output, layer):\n",
    "        if(layer != int_layer):\n",
    "            return output\n",
    "        functional.untuple(output)[:, subj_idx] = h \n",
    "        return output\n",
    "    return edit_output\n",
    "\n",
    "prompt = operator.prompt_template.format(source.subject)\n",
    "\n",
    "h_index, inputs = functional.find_subject_token_index(\n",
    "    mt=mt,\n",
    "    prompt=prompt,\n",
    "    subject=source.subject,\n",
    ")\n",
    "\n",
    "h_layer, z_layer = models.determine_layer_paths(model = mt, layers = [layer, -1])\n",
    "\n",
    "with baukit.TraceDict(\n",
    "    mt.model, layers = [h_layer, z_layer],\n",
    "    edit_output=get_intervention(\n",
    "#         h = hs_and_zs.h_by_subj[source.subject],         # let the computation proceed as usual\n",
    "        h = hs_and_zs.h_by_subj[source.subject] + delta_s, # replace s with s + delta_s\n",
    "        int_layer = h_layer, \n",
    "        subj_idx = h_index\n",
    "    )\n",
    ") as traces:\n",
    "    outputs = mt.model(\n",
    "        input_ids = inputs.input_ids,\n",
    "        attention_mask = inputs.attention_mask,\n",
    "    )\n",
    "\n",
    "lens.interpret_logits(\n",
    "    mt = mt, \n",
    "    logits = outputs.logits[0][-1], \n",
    "    get_proba=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c272c1",
   "metadata": {},
   "source": [
    "## Measuring causality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "51efa257",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.editors import LowRankPInvEditor\n",
    "\n",
    "svd = torch.svd(operator.weight.float())\n",
    "editor = LowRankPInvEditor(\n",
    "    lre=operator,\n",
    "    rank=rank,\n",
    "    svd=svd,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "88be35dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping accounting -> women | edit result= women (p=0.576) | success=(✓)\n",
      "Mapping anthropology -> men | edit result= men (p=0.536) | success=(✓)\n",
      "Mapping architecture -> women | edit result= men (p=0.524) | success=(✗)\n",
      "Mapping astronomy -> women | edit result= women (p=0.891) | success=(✓)\n",
      "Mapping business -> women | edit result= women (p=0.687) | success=(✓)\n",
      "Mapping communications -> men | edit result= men (p=0.512) | success=(✓)\n",
      "Mapping astronomy -> women | edit result= women (p=0.891) | success=(✓)\n",
      "Mapping business -> women | edit result= women (p=0.687) | success=(✓)\n",
      "Mapping communications -> men | edit result= men (p=0.512) | success=(✓)\n",
      "Mapping culinary arts -> men | edit result= women (p=0.532) | success=(✗)\n",
      "Mapping economics -> women | edit result= women (p=0.539) | success=(✓)\n",
      "Mapping education -> men | edit result= men (p=0.567) | success=(✓)\n",
      "Mapping culinary arts -> men | edit result= women (p=0.532) | success=(✗)\n",
      "Mapping economics -> women | edit result= women (p=0.539) | success=(✓)\n",
      "Mapping education -> men | edit result= men (p=0.567) | success=(✓)\n",
      "Mapping electrical engineering -> women | edit result= women (p=0.873) | success=(✓)\n",
      "Mapping engineering -> women | edit result= women (p=0.723) | success=(✓)\n",
      "Mapping environmental science -> men | edit result= men (p=0.577) | success=(✓)\n",
      "Mapping electrical engineering -> women | edit result= women (p=0.873) | success=(✓)\n",
      "Mapping engineering -> women | edit result= women (p=0.723) | success=(✓)\n",
      "Mapping environmental science -> men | edit result= men (p=0.577) | success=(✓)\n",
      "Mapping fashion design -> men | edit result= women (p=0.480) | success=(✗)\n",
      "Mapping fine arts -> men | edit result= men (p=0.714) | success=(✓)\n",
      "Mapping human resources -> men | edit result= men (p=0.587) | success=(✓)\n",
      "Mapping fashion design -> men | edit result= women (p=0.480) | success=(✗)\n",
      "Mapping fine arts -> men | edit result= men (p=0.714) | success=(✓)\n",
      "Mapping human resources -> men | edit result= men (p=0.587) | success=(✓)\n",
      "Mapping interior design -> men | edit result= men (p=0.482) | success=(✓)\n",
      "Mapping literature -> men | edit result= men (p=0.569) | success=(✓)\n",
      "Mapping marine biology -> men | edit result= women (p=0.474) | success=(✗)\n",
      "Mapping interior design -> men | edit result= men (p=0.482) | success=(✓)\n",
      "Mapping literature -> men | edit result= men (p=0.569) | success=(✓)\n",
      "Mapping marine biology -> men | edit result= women (p=0.474) | success=(✗)\n",
      "Mapping mathematics -> women | edit result= women (p=0.879) | success=(✓)\n",
      "Mapping mechanical engineering -> women | edit result= women (p=0.750) | success=(✓)\n",
      "Mapping nursing -> men | edit result= men (p=0.580) | success=(✓)\n",
      "Mapping mathematics -> women | edit result= women (p=0.879) | success=(✓)\n",
      "Mapping mechanical engineering -> women | edit result= women (p=0.750) | success=(✓)\n",
      "Mapping nursing -> men | edit result= men (p=0.580) | success=(✓)\n",
      "Mapping political science -> women | edit result= women (p=0.618) | success=(✓)\n",
      "Mapping psychology -> men | edit result= women (p=0.582) | success=(✗)\n",
      "Mapping public relations -> men | edit result= men (p=0.623) | success=(✓)\n",
      "Mapping political science -> women | edit result= women (p=0.618) | success=(✓)\n",
      "Mapping psychology -> men | edit result= women (p=0.582) | success=(✗)\n",
      "Mapping public relations -> men | edit result= men (p=0.623) | success=(✓)\n",
      "Mapping social work -> men | edit result= men (p=0.522) | success=(✓)\n",
      "Mapping sociology -> men | edit result= men (p=0.543) | success=(✓)\n",
      "------------------------------------------------------------\n",
      "Causality (@1) = 0.8076923076923077\n",
      "------------------------------------------------------------\n",
      "Mapping social work -> men | edit result= men (p=0.522) | success=(✓)\n",
      "Mapping sociology -> men | edit result= men (p=0.543) | success=(✓)\n",
      "------------------------------------------------------------\n",
      "Causality (@1) = 0.8076923076923077\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# precomputing latents to speed things up\n",
    "hs_and_zs = functional.compute_hs_and_zs(\n",
    "    mt = mt,\n",
    "    prompt_template = operator.prompt_template,\n",
    "    subjects = [sample.subject for sample in test.samples],\n",
    "    h_layer= operator.h_layer,\n",
    "    z_layer=-1,\n",
    "    batch_size = 2\n",
    ")\n",
    "\n",
    "success = 0\n",
    "fails = 0\n",
    "\n",
    "for sample in test.samples:\n",
    "    target = test_targets.get(sample)\n",
    "    assert target is not None\n",
    "    edit_result = editor(\n",
    "        subject = sample.subject,\n",
    "        target = target.subject\n",
    "    )\n",
    "    \n",
    "    success_flag = functional.is_nontrivial_prefix(\n",
    "        prediction=edit_result.predicted_tokens[0].token, target=target.object\n",
    "    )\n",
    "    \n",
    "    print(f\"Mapping {sample.subject} -> {target.object} | edit result={edit_result.predicted_tokens[0]} | success=({functional.get_tick_marker(success_flag)})\")\n",
    "    \n",
    "    success += success_flag\n",
    "    fails += not success_flag\n",
    "    \n",
    "causality = success / (success + fails)\n",
    "\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(f\"Causality (@1) = {causality}\")\n",
    "print(\"------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c587ae85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d6d2a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
